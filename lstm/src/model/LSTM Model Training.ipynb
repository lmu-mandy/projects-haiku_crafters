{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../../../')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils import one_hot_encode, get_batches, get_lookup_tables\n",
    "from model import CharRNN, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../../data/text/shakespeare.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize characters based on the passed in text corpus/data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = tuple(set(text))\n",
    "int2char, char2int = get_lookup_tables(text)\n",
    "encoded = np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training function along with hyper-parameters for model-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(net, data, epochs=10, n_seqs=10, n_steps=50, lr=0.001, clip=5, val_frac=0.1, cuda=False, print_every=10):\n",
    "    ''' Traing a network \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        net: CharRNN network\n",
    "        data: text data to train the network\n",
    "        epochs: Number of epochs to train\n",
    "        n_seqs: Number of mini-sequences per mini-batch, aka batch size\n",
    "        n_steps: Number of character steps per mini-batch\n",
    "        lr: learning rate\n",
    "        clip: gradient clipping\n",
    "        val_frac: Fraction of data to hold out for validation\n",
    "        cuda: Train with CUDA on a GPU\n",
    "        print_every: Number of steps for printing training and validation loss\n",
    "\n",
    "        Other Hyperparatmers \n",
    "        --------------------\n",
    "\n",
    "        Optimizer: Adam\n",
    "        Criterion: Cross Entropy Loss\n",
    "    '''\n",
    "    \n",
    "    net.train()\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # create training and validation data\n",
    "    val_idx = int(len(data)*(1-val_frac))\n",
    "    data, val_data = data[:val_idx], data[val_idx:]\n",
    "    print(\"Cuda: \", cuda)\n",
    "    if cuda:\n",
    "        net.to(\"cuda:0\")\n",
    "    \n",
    "    counter = 0\n",
    "    n_chars = len(net.chars)\n",
    "    for e in range(epochs):\n",
    "        h = net.init_hidden(n_seqs)\n",
    "        for x, y in get_batches(data, n_seqs, n_steps):\n",
    "            counter += 1\n",
    "            \n",
    "            # One-hot encode our data and make them Torch tensors\n",
    "            x = one_hot_encode(x, n_chars)\n",
    "            x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            inputs, targets = Variable(x), Variable(y)\n",
    "            if cuda:\n",
    "                inputs, targets = inputs.to(\"cuda:0\"), targets.to(\"cuda:0\")\n",
    "            targets = targets.type(torch.LongTensor)\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([Variable(each.data) for each in h])\n",
    "\n",
    "            net.zero_grad()\n",
    "            \n",
    "            output, h = net.forward(inputs, h)\n",
    "            temp =  targets.view(n_seqs*n_steps).to(\"cuda:0\") if cuda else targets.view(n_seqs*n_steps)\n",
    "            if cuda:\n",
    "                output.to(\"cuda:0\")\n",
    "            \n",
    "            loss = criterion(output, temp)\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "\n",
    "            opt.step()\n",
    "            \n",
    "            if counter % print_every == 0:\n",
    "                \n",
    "                # Get validation loss\n",
    "                val_h = net.init_hidden(n_seqs)\n",
    "                val_losses = []\n",
    "                for x, y in get_batches(val_data, n_seqs, n_steps):\n",
    "                    # One-hot encode our data and make them Torch tensors\n",
    "                    x = one_hot_encode(x, n_chars)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    \n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                    val_h = tuple([Variable(each.data, volatile=True) for each in val_h])\n",
    "                    \n",
    "                    inputs, targets = Variable(x, volatile=True), Variable(y, volatile=True)\n",
    "                    if cuda:\n",
    "                        inputs, targets = inputs.to(\"cuda:0\"), targets.to(\"cuda:0\")\n",
    "                    targets = targets.type(torch.LongTensor)\n",
    "\n",
    "                    output, val_h = net.forward(inputs, val_h)\n",
    "                    temp2 = targets.view(n_seqs*n_steps).to(\"cuda:0\") if cuda else targets.view(n_seqs*n_steps)\n",
    "                    if cuda:\n",
    "                        output.to(\"cuda:0\")\n",
    "                    \n",
    "                    val_loss = criterion(output, temp2)\n",
    "                \n",
    "                    val_losses.append(val_loss.data.item())\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.data.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
    "    \n",
    "    return np.mean(val_losses)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = CharRNN(chars, n_hidden=512, n_layers=2)\n",
    "if use_cuda:\n",
    "    net.to(\"cuda:0\")\n",
    "else:\n",
    "    net.to(\"cpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!Cuda:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_26420\\1293081943.py:63: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(net.parameters(), clip)\n",
      "C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_26420\\1293081943.py:79: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  val_h = tuple([Variable(each.data, volatile=True) for each in val_h])\n",
      "C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_26420\\1293081943.py:81: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  inputs, targets = Variable(x, volatile=True), Variable(y, volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10... Step: 10... Loss: 3.3890... Val Loss: 3.4200\n",
      "Epoch: 1/10... Step: 20... Loss: 3.2623... Val Loss: 3.2827\n",
      "Epoch: 1/10... Step: 30... Loss: 3.1177... Val Loss: 3.1144\n",
      "Epoch: 1/10... Step: 40... Loss: 2.9598... Val Loss: 2.9250\n",
      "Epoch: 1/10... Step: 50... Loss: 2.7587... Val Loss: 2.7448\n",
      "Epoch: 1/10... Step: 60... Loss: 2.6399... Val Loss: 2.6175\n",
      "Epoch: 1/10... Step: 70... Loss: 2.5314... Val Loss: 2.5472\n",
      "Epoch: 2/10... Step: 80... Loss: 2.5023... Val Loss: 2.4904\n",
      "Epoch: 2/10... Step: 90... Loss: 2.4492... Val Loss: 2.4532\n",
      "Epoch: 2/10... Step: 100... Loss: 2.4133... Val Loss: 2.4195\n",
      "Epoch: 2/10... Step: 110... Loss: 2.3862... Val Loss: 2.3971\n",
      "Epoch: 2/10... Step: 120... Loss: 2.3431... Val Loss: 2.3691\n",
      "Epoch: 2/10... Step: 130... Loss: 2.3261... Val Loss: 2.3402\n",
      "Epoch: 2/10... Step: 140... Loss: 2.2956... Val Loss: 2.3252\n",
      "Epoch: 2/10... Step: 150... Loss: 2.2696... Val Loss: 2.3031\n",
      "Epoch: 3/10... Step: 160... Loss: 2.2495... Val Loss: 2.2811\n",
      "Epoch: 3/10... Step: 170... Loss: 2.2368... Val Loss: 2.2749\n",
      "Epoch: 3/10... Step: 180... Loss: 2.1855... Val Loss: 2.2649\n",
      "Epoch: 3/10... Step: 190... Loss: 2.2527... Val Loss: 2.2706\n",
      "Epoch: 3/10... Step: 200... Loss: 2.1946... Val Loss: 2.2512\n",
      "Epoch: 3/10... Step: 210... Loss: 2.1501... Val Loss: 2.2353\n",
      "Epoch: 3/10... Step: 220... Loss: 2.1241... Val Loss: 2.2202\n",
      "Epoch: 3/10... Step: 230... Loss: 2.1142... Val Loss: 2.2069\n",
      "Epoch: 4/10... Step: 240... Loss: 2.1092... Val Loss: 2.1939\n",
      "Epoch: 4/10... Step: 250... Loss: 2.0971... Val Loss: 2.1888\n",
      "Epoch: 4/10... Step: 260... Loss: 2.0730... Val Loss: 2.1776\n",
      "Epoch: 4/10... Step: 270... Loss: 2.0723... Val Loss: 2.1728\n",
      "Epoch: 4/10... Step: 280... Loss: 2.0659... Val Loss: 2.1695\n",
      "Epoch: 4/10... Step: 290... Loss: 2.0557... Val Loss: 2.1509\n",
      "Epoch: 4/10... Step: 300... Loss: 2.0077... Val Loss: 2.1435\n",
      "Epoch: 4/10... Step: 310... Loss: 1.9955... Val Loss: 2.1328\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\brand\\Desktop\\Github Repos\\NLP\\projects-haiku_crafters\\lstm\\src\\model\\TorchRNN copy.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/Github%20Repos/NLP/projects-haiku_crafters/lstm/src/model/TorchRNN%20copy.ipynb#ch0000005?line=0'>1</a>\u001b[0m n_seqs, n_steps \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m, \u001b[39m100\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/Github%20Repos/NLP/projects-haiku_crafters/lstm/src/model/TorchRNN%20copy.ipynb#ch0000005?line=1'>2</a>\u001b[0m train(net, encoded, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, n_seqs\u001b[39m=\u001b[39;49mn_seqs, n_steps\u001b[39m=\u001b[39;49mn_steps, lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m, cuda\u001b[39m=\u001b[39;49muse_cuda, print_every\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\brand\\Desktop\\Github Repos\\NLP\\projects-haiku_crafters\\lstm\\src\\model\\TorchRNN copy.ipynb Cell 6'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, data, epochs, n_seqs, n_steps, lr, clip, val_frac, cuda, print_every)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/Github%20Repos/NLP/projects-haiku_crafters/lstm/src/model/TorchRNN%20copy.ipynb#ch0000003?line=83'>84</a>\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mLongTensor)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/Github%20Repos/NLP/projects-haiku_crafters/lstm/src/model/TorchRNN%20copy.ipynb#ch0000003?line=85'>86</a>\u001b[0m output, val_h \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mforward(inputs, val_h)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/Github%20Repos/NLP/projects-haiku_crafters/lstm/src/model/TorchRNN%20copy.ipynb#ch0000003?line=86'>87</a>\u001b[0m temp2 \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39;49mview(n_seqs\u001b[39m*\u001b[39;49mn_steps)\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mif\u001b[39;00m cuda \u001b[39melse\u001b[39;00m targets\u001b[39m.\u001b[39mview(n_seqs\u001b[39m*\u001b[39mn_steps)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/Github%20Repos/NLP/projects-haiku_crafters/lstm/src/model/TorchRNN%20copy.ipynb#ch0000003?line=87'>88</a>\u001b[0m \u001b[39mif\u001b[39;00m cuda:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brand/Desktop/Github%20Repos/NLP/projects-haiku_crafters/lstm/src/model/TorchRNN%20copy.ipynb#ch0000003?line=88'>89</a>\u001b[0m     output\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "n_seqs, n_steps = 128, 100\n",
    "train(net, encoded, epochs=10, n_seqs=n_seqs, n_steps=n_steps, lr=0.001, cuda=use_cuda, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = {'n_hidden': net.n_hidden,\n",
    "              'n_layers': net.n_layers,\n",
    "              'state_dict': net.state_dict(),\n",
    "              'tokens': net.chars}\n",
    "with open('rnn.net', 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brand\\Desktop\\Github Repos\\NLP\\projects-haiku_crafters\\lstm\\src\\model\\model.py:65: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  inputs = Variable(torch.from_numpy(x), volatile=True)\n",
      "c:\\Users\\brand\\Desktop\\Github Repos\\NLP\\projects-haiku_crafters\\lstm\\src\\model\\model.py:69: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  h = tuple([Variable(each.data, volatile=True) for each in h])\n",
      "c:\\Users\\brand\\Desktop\\Github Repos\\NLP\\projects-haiku_crafters\\lstm\\src\\model\\model.py:72: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(out).data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'roses of word, as of thou anf thou suptency for this we thim.\\n\\nBUCKINGHAM:\\nI, a b'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output sample after-training model\n",
    "haiku = (sample(net, 75, cuda=True, top_k=10, prime=\"roses\"))\n",
    "haiku"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
